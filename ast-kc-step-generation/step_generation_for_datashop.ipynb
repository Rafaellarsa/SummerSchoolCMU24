{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad2b754",
   "metadata": {},
   "source": [
    "## Setting Custom Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ef3a2",
   "metadata": {},
   "source": [
    "Modify the following parameters according to your folder organization. Example files for each folder can be found in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f81722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTOR_SOLUTIONS = \"./instructor_solutions\"\n",
    "STUDENT_INTERACTION_DATA = \"./student_interaction_data\"\n",
    "OUTPUT_FOLDER = \"./datasets/experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdd8cd",
   "metadata": {},
   "source": [
    "Select the number of students to be sampled from the set. Must be less than the total number of students in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d9017c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_SAMPLE_SIZE = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2704da",
   "metadata": {},
   "source": [
    "List of semesters the data was collected from. Must match the names of the subfolders in STUDENT_INTERACTION_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de30a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_SEMESTERS = ['semester']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c68464",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad8f5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from graphs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a671b2",
   "metadata": {},
   "source": [
    "##Â Generate ASTs for Solution Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aa716e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f86fc7b4b44a5db0ab0094f95ba903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sol_path = INSTRUCTOR_SOLUTIONS\n",
    "sol_trees = {}\n",
    "solutions = {}\n",
    "for file in tqdm(os.listdir(sol_path)):\n",
    "    try:\n",
    "        with open(os.path.join(sol_path, file), 'rb') as f:\n",
    "            program = f.read().decode(\"utf-8-sig\").encode(\"utf-8\")\n",
    "        solutions[file[:-3]] = [program]\n",
    "    except:\n",
    "        print(\"Error while reading instructor solution:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a044e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_correct_submissions(problemName):\n",
    "    '''\n",
    "    Helper function for filtering a DataFrame for correct student submissions.\n",
    "    '''\n",
    "    return data[(data['Score'] == 1.0) & (data['ProblemName'] == problemName)]['Input'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e08453a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ccf23a591f40169db11364eb0d64bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m problemName \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProblemName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m---> 12\u001b[0m     problemInput \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_correct_submissions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblemName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m problemName \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m solutions:\n\u001b[1;32m     14\u001b[0m         solutions[problemName] \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mreturn_correct_submissions\u001b[0;34m(problemName)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturn_correct_submissions\u001b[39m(problemName):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Helper function for filtering a DataFrame for correct student submissions.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProblemName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproblemName\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input'"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(STUDENT_INTERACTION_DATA):\n",
    "    if len(dirs) > 0:\n",
    "        continue\n",
    "    users = {} \n",
    "    np.random.seed(42)\n",
    "    random_set = None\n",
    "    for file in tqdm(files):\n",
    "        data = pd.read_csv(os.path.join(root, file))\n",
    "        if len(data) <= 0:\n",
    "            continue\n",
    "        for problemName in data['ProblemName'].unique():\n",
    "            problemInput = return_correct_submissions(problemName)\n",
    "            if problemName not in solutions:\n",
    "                solutions[problemName] = []\n",
    "            solutions[problemName].extend(problemInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143a466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301304db4be34844b2667076222c9a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n",
      "Error while parsing AST - returning empty tree...\n"
     ]
    }
   ],
   "source": [
    "solutions_embedded = {}\n",
    "solutions_traversal = {}\n",
    "tfidf_params = {}\n",
    "for problem in tqdm(solutions):\n",
    "    def parser_handler(content):\n",
    "        try:\n",
    "            return ast.parse(content)\n",
    "        except:\n",
    "            print(\"Error while parsing AST - returning empty tree...\")\n",
    "            return ast.Module()\n",
    "    ast_trees = [parser_handler(solution) for solution in solutions[problem]]\n",
    "    tfidf_vectors, all_nodes, idf = compute_tfidf(ast_trees)\n",
    "    solutions_embedded[problem] = tfidf_vectors\n",
    "    solutions_traversal[problem] = [dfs_traversal(tree) for tree in ast_trees]\n",
    "    tfidf_params[problem] = (all_nodes, idf) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827347e8",
   "metadata": {},
   "source": [
    "## Compare Student Submission to the Solution Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66701ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "def get_list_of_nodes(programName, dataInput):\n",
    "    return \":\"\n",
    "    if programName not in solutions:\n",
    "        return \":\"\n",
    "\n",
    "    min_op = 50\n",
    "    try:\n",
    "        submission = ast.parse(dataInput)\n",
    "        raise Exception\n",
    "    except:\n",
    "        submission = None\n",
    "        target = ast.parse(solutions[programName][0])\n",
    "        incorrect_ops = tree_edit_distance_with_operations(target, submission)\n",
    "    else:\n",
    "        # find two closest candidates for comparing the trees\n",
    "        submission_vec = compute_tfidf_ood(submission, *tfidf_params[programName])\n",
    "        dfs_tree = dfs_traversal(submission)\n",
    "        d_tfidf = []\n",
    "        for vec in solutions_embedded[programName]:\n",
    "            d_tfidf.append(euclidean_distance(submission_vec, vec))\n",
    "\n",
    "        sort_counter = 0\n",
    "        indice = np.argmin(d_tfidf)\n",
    "        while True:\n",
    "            sort_counter += 1\n",
    "            try:\n",
    "                sol_tfidf = solutions[programName][indice]\n",
    "                _ = ast.parse(sol_tfidf)\n",
    "                break\n",
    "            except:\n",
    "                indice = np.argsort(d_tfidf)[sort_counter:][0]\n",
    "\n",
    "\n",
    "        d_align = []\n",
    "        for tree in (solutions_traversal[programName]):\n",
    "            d_align.append(calculate_dissimilarity(dfs_tree, tree))\n",
    "        sol_align = solutions[programName][np.argmin(d_align)]\n",
    "        ops_tfidf = tree_edit_distance_with_operations(ast.parse(sol_tfidf), submission)\n",
    "\n",
    "        incorrect_ops = ops_tfidf\n",
    "        target = ast.parse(sol_tfidf)\n",
    "        \n",
    "\n",
    "    correct_ops = set_of_children(target).difference(incorrect_ops)\n",
    "    l = ','.join(list(correct_ops) + list(incorrect_ops)) + ':' + ','.join('1'*len(correct_ops)+'0'*len(incorrect_ops))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98316781",
   "metadata": {},
   "source": [
    "## Generate Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63124d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'Transaction Id',\n",
    "    'Anon Student Id',\n",
    "    'Session Id', # set to 1 for all\n",
    "    'Time',\n",
    "    'Level (Unit)', # homework no\n",
    "    'Problem Name',\n",
    "    'Problem Start Time',\n",
    "    'Input',\n",
    "    'Step Name',\n",
    "    'Outcome',\n",
    "    'KC (Binary-Node)',\n",
    "    'KC Category (Binary-Node)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import md5\n",
    "\n",
    "def string_hash(string):\n",
    "    return md5(string.encode()).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a71961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "counters = defaultdict(int)\n",
    "\n",
    "user_counts = {semester:{} for semester in LIST_OF_SEMESTERS}\n",
    "\n",
    "import string\n",
    "table = str.maketrans('', '', string.ascii_lowercase)\n",
    "\n",
    "def user_counter(anonid, semester):\n",
    "    if anonid not in user_counts[semester]:\n",
    "        counters[semester] += 1\n",
    "        user_counts[semester][anonid] = f\"{semester.translate(table)}-S{counters[semester]:05d}\"\n",
    "    return user_counts[semester][anonid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_import_csv(data, semester, random_set=None):\n",
    "    df = pd.DataFrame()\n",
    "    df[cols[1]] = data['AnonID'].apply(user_counter, args=(semester,))\n",
    "    \n",
    "    if random_set is not None:\n",
    "        df = df[df['Anon Student Id'].isin(random_set)]\n",
    "    \n",
    "    df[cols[2]] = 1\n",
    "    df[cols[3]] = data['Timestamp']\n",
    "    df[cols[4]] = data['Assessment']\n",
    "    df[cols[5]] = data['ProblemName']\n",
    "    df[cols[6]] = data['Timestamp'] # str apply [:-6]\n",
    "    tqdm.pandas()\n",
    "\n",
    "    series = data.progress_apply(lambda x: get_list_of_nodes(x['ProblemName'], x['Input']), axis=1)\n",
    "\n",
    "    df[cols[9]] = series.apply(lambda x: x.split(':')[1])\n",
    "    df[cols[10]] = series.apply(lambda x: x.split(':')[0])\n",
    "\n",
    "    df[cols[11]] = ''\n",
    "    df = df.drop_duplicates(subset=[cols[1], cols[5]])\n",
    "    df = df.assign(**{cols[10]: df[cols[10]].str.split(','),\n",
    "                      cols[9]: df[cols[9]].str.split(',').apply(lambda x: x if '' in x else [float(i) for i in x])}).explode(\n",
    "        [cols[10], cols[9]])\n",
    "    df[cols[9]] = df[cols[9]].apply(lambda x: 'CORRECT' if x == 1.0 else 'INCORRECT')\n",
    "    df[cols[8]] = df[cols[10]]\n",
    "\n",
    "    df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5a47a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fc587766f54091956bcd0bddf369fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9017ac0ec345438caf13fe56be029015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(STUDENT_INTERACTION_DATA):\n",
    "    if len(dirs) > 0:\n",
    "        continue\n",
    "    users = {} \n",
    "    np.random.seed(42)\n",
    "    random_set = None\n",
    "    student_list = []\n",
    "    for file in tqdm(files):\n",
    "        data = pd.read_csv(os.path.join(root, file))\n",
    "        if len(data) <= 0:\n",
    "            continue\n",
    "        df = populate_import_csv(data, root.split('/')[-1], random_set)\n",
    "        if random_set is None:\n",
    "            random_set = np.random.choice(df['Anon Student Id'].unique(), len(df['Anon Student Id'].unique()), replace=False)\n",
    "            df = df[df['Anon Student Id'].isin(random_set)]\n",
    "        student_list.extend(df['Anon Student Id'].unique())\n",
    "        os.makedirs(os.path.join(OUTPUT_FOLDER, root.split('/')[-1]), exist_ok=True)\n",
    "        df.to_csv(os.path.join(OUTPUT_FOLDER, root.split('/')[-1], file[:-4] + '.txt'), sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
